{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download -c ds3-which-whisky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>pert_alcohol</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dave Broom</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>42.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>97</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Davin de Kergommeaux</td>\n",
       "      <td>After 40 years in barrels, the trademark Canad...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>96</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                author  \\\n",
       "0   1          John Hansell   \n",
       "1   2            Dave Broom   \n",
       "2   3          John Hansell   \n",
       "3   4          John Hansell   \n",
       "4   6  Davin de Kergommeaux   \n",
       "\n",
       "                                         description    price  ratingValue  \\\n",
       "0  A marriage of 13 and 18 year old bourbons. A m...     85.0           97   \n",
       "1  There have been some legendary Bowmores from t...  13500.0           97   \n",
       "2  This bottling celebrates master distiller Park...    150.0           97   \n",
       "3  What impresses me most is how this whisky evol...   4500.0           97   \n",
       "4  After 40 years in barrels, the trademark Canad...    199.0           96   \n",
       "\n",
       "   pert_alcohol  category  \n",
       "0          51.5       2.0  \n",
       "1          42.9       1.0  \n",
       "2          50.0       2.0  \n",
       "3          40.5       1.0  \n",
       "4          45.0       NaN  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Identities\n",
    "\n",
    "It is important to note which categories refer to which. I want to use this to extract extra meaning from the description column in order to boost model performance.]\n",
    "\n",
    "> 1 = Scotch  \n",
    "> 2 = Bourbon  \n",
    "> 3 = Craft  \n",
    "> 4 = Canadian  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1637\n",
       "2.0     449\n",
       "3.0     300\n",
       "4.0     200\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for class imbalance\n",
    "\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "author            0\n",
       "description       0\n",
       "price            63\n",
       "ratingValue       0\n",
       "pert_alcohol     60\n",
       "category        288\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before digging into the primary features, namely the description. I'd like to look at whether there is any noteable difference between ratings, alcohol percentage and price. If the primary statistical measurements show any significant variation, it would be worth it to include them in the modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_info(data):\n",
    "    print('###################')\n",
    "    print('mean:   ', data.mean())\n",
    "    print('median: ', data.median())\n",
    "    print('mode :  ', data.mode()[0])\n",
    "    print('StDev:  ', data.std())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Prices ########\n",
      "Categeory  =  1\n",
      "###################\n",
      "mean:    327.81806696146555\n",
      "median:  110.0\n",
      "mode :   100.0\n",
      "StDev:   1288.8296456971598\n",
      "\n",
      "Categeory  =  2\n",
      "###################\n",
      "mean:    70.10467706013362\n",
      "median:  50.0\n",
      "mode :   47.0\n",
      "StDev:   69.47337105763614\n",
      "\n",
      "Categeory  =  3\n",
      "###################\n",
      "mean:    56.873333333333335\n",
      "median:  47.0\n",
      "mode :   50.0\n",
      "StDev:   52.47280508161027\n",
      "\n",
      "Categeory  =  4\n",
      "###################\n",
      "mean:    58.3725\n",
      "median:  38.5\n",
      "mode :   70.0\n",
      "StDev:   74.12604702795065\n",
      "\n",
      "\n",
      "\n",
      "###### Ratings ########\n",
      "Categeory  =  1\n",
      "###################\n",
      "mean:    86.58399511301161\n",
      "median:  87.0\n",
      "mode :   86\n",
      "StDev:   4.039210375758337\n",
      "\n",
      "Categeory  =  2\n",
      "###################\n",
      "mean:    87.89755011135857\n",
      "median:  89.0\n",
      "mode :   90\n",
      "StDev:   5.170591485127886\n",
      "\n",
      "Categeory  =  3\n",
      "###################\n",
      "mean:    83.23\n",
      "median:  84.0\n",
      "mode :   84\n",
      "StDev:   4.0873121242863\n",
      "\n",
      "Categeory  =  4\n",
      "###################\n",
      "mean:    85.465\n",
      "median:  86.0\n",
      "mode :   88\n",
      "StDev:   5.462413827615096\n",
      "\n",
      "\n",
      "\n",
      "###### % Alcohol ########\n",
      "Categeory  =  1\n",
      "###################\n",
      "mean:    48.375307788944724\n",
      "median:  46.0\n",
      "mode :   46.0\n",
      "StDev:   5.8119893556128455\n",
      "\n",
      "Categeory  =  2\n",
      "###################\n",
      "mean:    49.67486516853932\n",
      "median:  46.5\n",
      "mode :   45.0\n",
      "StDev:   7.53708191614025\n",
      "\n",
      "Categeory  =  3\n",
      "###################\n",
      "mean:    46.3071906354515\n",
      "median:  45.0\n",
      "mode :   45.0\n",
      "StDev:   5.632796473141159\n",
      "\n",
      "Categeory  =  4\n",
      "###################\n",
      "mean:    43.51701030927835\n",
      "median:  40.0\n",
      "mode :   40.0\n",
      "StDev:   5.7266280423687785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('###### Prices ########')\n",
    "for i in np.arange(1,5):\n",
    "    print('Categeory  = ', i)\n",
    "    price_info(df[df['category'] == i]['price'])\n",
    "\n",
    "print('\\n\\n###### Ratings ########')\n",
    "for i in np.arange(1,5):\n",
    "    print('Categeory  = ', i)\n",
    "    price_info(df[df['category'] == i]['ratingValue'])\n",
    "    \n",
    "print('\\n\\n###### % Alcohol ########')\n",
    "for i in np.arange(1,5):\n",
    "    print('Categeory  = ', i)\n",
    "    price_info(df[df['category'] == i]['pert_alcohol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that price and percent alcohol don't vary much. That makes sense as most whisk(e)y's generally sit between 40% and 61%. Canadian whiskey tends to be 40% whereas the upper limit for most scotches is 52. However, many overproof american whiskeys like Bottled in Bond and Cask Strengths may also sit around the scotch level. Only the really insane stuff like Booker's reaches the vaunted 61%. \n",
    "\n",
    "> Given the lack of variety and existence of null values in the validation set, I will remove the percent_alcohol and rating feature\n",
    "\n",
    "Price is staying despite it's null values because it shows a marked difference between classes, specifically identifying Scotch. \n",
    "\n",
    "This can then be imputed based on the next engineered features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['ratingValue','pert_alcohol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Key Terms\n",
    "\n",
    "Given these are reviews, there is a pretty significant amount of leakage in the desciption text. They often provide keywords that are associated with the specified field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scotch\n",
    "\n",
    "The first row that is classified as a Scotch is this one. It lists the name Bowmore which is a distiller from the isle of Islay that utilizes sherry finished on their characteristically smokey scotches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There have been some legendary Bowmores from the mid-60s and this is every bit their equal. All of them share a remarkable aroma of tropical fruit, which here moves into hallucinatory intensity: guava, mango, peach, pineapple, grapefruit. There’s a very light touch of peat smoke, more a memory of Islay than the reality. Concentrated; even at low strength the palate is silky, heady, and haunting, and lasts forever in the dry glass. A legend is born. (Eight bottles only for the U.S.) Editor's Choice.\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category'] == 1]['description'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bourbon\n",
    "\n",
    "The Bourbon is harder to identify. It relied on name recongnition. Either the distiller or the distillery will be mentioned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This bottling celebrates master distiller Parker Beam's 50 years of service by including whiskey from each of the past five decades. This is a fabulous whiskey: seamless and incredibly complex, with an impeccable marriage of youth and maturity. It’s also very even-keeled throughout -- quite different than last year’s equally impressive PHC, a 27 year old, whose personality was more like an exhilarating old wooden rollercoaster ride (and also brandished more oak).\\xa0Look for candied citrus, nectarine, blueberry, and sultana anchored by a nougat center, laced with honeyed vanilla and orange creamsicle. There’s a dusting of cocoa powder, brittle mint, and cinnamon, too. Tobacco leaves, polished leather, and teasing bourbon barrel char round out the palate, emerging more prominently towards a warming finish. A classic!\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category'] == 2]['description'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Craft Whiskey\n",
    "\n",
    "Craft distilleries are harder to identify. Often times they will source from all over the place. This will lead to a hodgepodge of distilleries. If anything this is the wildcard. It may be best to ignore this feature alltogether in case any feature engineering confuses the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A sourced whiskey of 95% corn, finished in wine barrels from winemaker Dave Phinney. This makes a super first impression, with Bit-O-Honey candy, eucalyptus, black cherry, cinnamon hearts, violet candies, and sandalwood. The flavors pour layered and complex, with clove-studded orange, flickers of rye spice, and pure, crystalline sweetness balanced with lemony lift. Laser-like spice, sweet caramel corn, and more floral notes dance across the long finish.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category'] == 3]['description'][391]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canadian Whiskey\n",
    "\n",
    "Canada sources a lot of whiskey to the United States craft distilleries. I have to be careful about classifying Rye or Canada as it is often mentioned in the craft classes. On top of that, almost all Canadian whiskeys are blends of multiple distilleries. it might be good to identify Canadian Brands rather than regions or distilleries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corby’s latest Lot 40, this one undated, comes from the same distillation batch as the 2012 release, but with a couple of extra years in wood. The familiar flavors are all there: dustiness, sour rye, hard wet slate, floral notes, exotic fruits, sweet spices, and biting white pepper. Over these, time has sprinkled licorice root, dried dates, oatmeal porridge, vanilla, hints of bike tires, and mango peels. Flavors remain fully integrated with faint tannins underscoring a long sour-rye finish. Value Pick.'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category'] == 4]['description'][93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Identification\n",
    "\n",
    "There are a lot of Scotch keywords so I am going to scrape those. The Canadian and Bourbon keywords I will recite by memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = requests.get(URL).text\n",
    "URL = requests.get('https://en.wikipedia.org/wiki/List_of_whisky_distilleries_in_Scotland').text\n",
    "\n",
    "soup = BeautifulSoup(URL,'html.parser')\n",
    "\n",
    "scotch_references = []\n",
    "\n",
    "soup = BeautifulSoup(URL,'html.parser')\n",
    "for items in soup.find('table', class_='wikitable').find_all('tr')[1::1]:\n",
    "    data = items.find_all(['th','td'])\n",
    "    try:\n",
    "        distillery = data[0].a.text\n",
    "    \n",
    "    except AttributeError:pass\n",
    "    except IndexError:pass\n",
    "    scotch_references.append(distillery)\n",
    "    \n",
    "other_scotch_references = ['loch','speyside','campbeltown',\n",
    "                           'highland','islay','orkney','skye']\n",
    "\n",
    "for keyword in other_scotch_references:\n",
    "    scotch_references.append(keyword)\n",
    "    \n",
    "bourbon_references = ['Kentucky','Bourbons','Lexington','Sazerac','Bardstown',\n",
    "                      'Buffalo Trace','1792','Colonel','Barton','Dixie','Stagg',\n",
    "                      'Winkle','Bowman','Blanton','Eagle Rare','E.H. Taylor',\n",
    "                      'Elmer T. Lee','Weller','Heaven Hill','Brown Forman', 'Beam',\n",
    "                      'Elijah Craig','Evan Williams','Old Fitzgerald','Basil Hayden']\n",
    "\n",
    "canadian_references = ['Alberta', 'Canadian Mist', 'Crown Royal','Forty Creek','Highwood'\n",
    "                       'Pendleton','Pemberton','Hiram Walker','Lot 40','Wiser','Seagram']\n",
    "\n",
    "bourbon_references = [x.lower() for x in bourbon_references]\n",
    "canadian_references = [x.lower() for x in canadian_references]\n",
    "scotch_references = [x.lower() for x in scotch_references]\n",
    "\n",
    "references = [bourbon_references, \n",
    "              canadian_references, \n",
    "              scotch_references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotch = []\n",
    "bourbon = []\n",
    "canadian = []\n",
    "\n",
    "for i in np.arange(len(df)):\n",
    "    for k in references:\n",
    "        ref_count = 0\n",
    "        for j in k:\n",
    "            if j in df['description'][i].lower():\n",
    "                ref_count += 1\n",
    "        if k == bourbon_references:\n",
    "            bourbon.append(ref_count)\n",
    "        elif k == scotch_references:\n",
    "            scotch.append(ref_count)\n",
    "        else:\n",
    "            canadian.append(ref_count)\n",
    "\n",
    "df['scotch_reference'] = scotch\n",
    "df['bourbon_reference'] = bourbon\n",
    "df['canadian_reference'] = canadian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Models\n",
    "\n",
    "Now that references to the data have been engineered into features, it is time to run some cross-validation and baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner():\n",
    "    \n",
    "    cleaned_entry = []\n",
    "    \n",
    "    for i in np.arange(len(df)):\n",
    "        \n",
    "        sample = df['description'][i]\n",
    "        soup = BeautifulSoup(sample, \"html.parser\")\n",
    "        \n",
    "        sample = (re.sub(r'[^a-zA-Z ^0-9]', '', \n",
    "                         soup.text))\n",
    "            \n",
    "        cleaned_entry.append(sample)\n",
    "\n",
    "    return cleaned_entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_line = df[['description','category']].dropna()\n",
    "X = b_line['description']\n",
    "y = b_line['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=10000,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', \n",
    "                        max_features = 10000)\n",
    "\n",
    "sgdc  = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', sgdc)])\n",
    "\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.5s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.6s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation baseline:  0.9412017547751871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "score_1 = (cross_val_score(pipe, X, y, \n",
    "                          cv = 10, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = -1,\n",
    "                          verbose = 10)).mean()\n",
    "\n",
    "print('cross validation baseline: ', score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ord',\n",
       "                 OrdinalEncoder(cols=['author'], drop_invariant=False,\n",
       "                                handle_missing='value', handle_unknown='value',\n",
       "                                mapping=[{'col': 'author',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': John Hansell               1\n",
       "Dave Broom                 2\n",
       "Fred Minnick               3\n",
       "Davin de Kergommeaux       4\n",
       "Gavin Smith                5\n",
       "Dominic Roskrow            6\n",
       "Geoffrey Kleinman          7\n",
       "Jonny McCormick            8\n",
       "Susannah Skiver Barton     9\n",
       "Lew Bryson                10\n",
       "Jeffery Lindenmut...\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, eval_metric='merror',\n",
       "                               gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "                               max_depth=25, min_child_weight=1, missing=None,\n",
       "                               n_estimators=200, n_jobs=-1, nthread=None,\n",
       "                               num_class=4, objective='multi:softprob',\n",
       "                               random_state=5, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, seed=42, silent=True,\n",
       "                               subsample=1, verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_2 = df[['author', 'price', 'scotch_reference', \n",
    "          'bourbon_reference', 'canadian_reference', \n",
    "          'category']].dropna()\n",
    "\n",
    "X = b_2.drop(columns = 'category')\n",
    "y = b_2['category']\n",
    "\n",
    "xgbc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "                        max_depth=25, min_child_weight=1, missing=None, n_estimators=200,\n",
    "                        n_jobs=-1, nthread=None, objective='multi:softmax',num_class=4,\n",
    "                        random_state=5, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "                        seed=42, silent=True, subsample=1, eval_metric='merror')\n",
    "\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "\n",
    "pipe_2 = Pipeline([('ord', encoder), ('clf', xgbc)])\n",
    "\n",
    "pipe_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.5s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.6s remaining:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second validation baseline:  0.9237384482078079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "score_2 = (cross_val_score(pipe_2, X, y, \n",
    "                          cv = 10, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = -1,\n",
    "                          verbose = 10)).mean()\n",
    "\n",
    "print('second validation baseline: ', score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the vectorized description model performed slightly better by utilizing a stochastic gradient descent classifier. The other features when seem to peform almost as good as the nlp vectorization when run through a gradient boosting tree ensemble. Now I am going to try to engineer a new dataframe that combines both. I can either use a feature union or concatentate the dataframe without a pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute null values for Price\n",
    "\n",
    "Since the validation dataset has a few null values for price, I want to impute the values of these bottles. Since these items are usually rare or collector's bottles, it'll they don't have a price, but tend to be expensive. Similarly, they appear to mostly refer to scotch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    54\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['price'].isnull() == True]['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    33\n",
       "1    29\n",
       "2     1\n",
       "Name: scotch_reference, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scotch references\n",
    "df[df['price'].isnull() == True]['scotch_reference'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    62\n",
       "1     1\n",
       "Name: bourbon_reference, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bourbon references\n",
    "df[df['price'].isnull() == True]['bourbon_reference'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63\n",
       "Name: canadian_reference, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Canadian references\n",
    "df[df['price'].isnull() == True]['canadian_reference'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it's safe to assume that these bottles are references to more obscure scotches. I am going to use the mean scotch price to impute the value there. I am also going to impute a few styles that reference certain categories in order to have a more robust training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].fillna(df[df['category'] == 1]['price'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[df['category'].isnull() == True].index:\n",
    "    if df['scotch_reference'][i] > 0:\n",
    "        df['category'][i] = 1\n",
    "    elif df['bourbon_reference'][i] > 0:\n",
    "        df['category'][i] = 2\n",
    "    elif df['canadian_reference'][i] > 0:\n",
    "        df['category'][i] = 4\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to drop any remaining rows that are not easily classifiable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to build the final training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2713, 2718) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>105</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>115</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>youthfulness</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zinfandel</th>\n",
       "      <th>zing</th>\n",
       "      <th>zingy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2718 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10  100  105   11  110  115   12  120  125  ...  younger  youngest  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
       "\n",
       "      youth  youthful  youthfulness  zest  zesty  zinfandel  zing  zingy  \n",
       "0  0.000000       0.0           0.0   0.0    0.0        0.0   0.0    0.0  \n",
       "1  0.000000       0.0           0.0   0.0    0.0        0.0   0.0    0.0  \n",
       "2  0.136695       0.0           0.0   0.0    0.0        0.0   0.0    0.0  \n",
       "3  0.000000       0.0           0.0   0.0    0.0        0.0   0.0    0.0  \n",
       "4  0.000000       0.0           0.0   0.0    0.0        0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 2718 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                        max_features = 5000, \n",
    "                        min_df=5)\n",
    "\n",
    "dtm = tfidf.fit_transform(df['description'])\n",
    "\n",
    "docs = (pd.DataFrame(dtm.todense(), \n",
    "                    columns=tfidf.get_feature_names())\n",
    "       .drop(columns = ['category','price']))\n",
    "\n",
    "print(docs.shape,'\\n')\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([df[['author', 'price', \n",
    "                          'category', 'scotch_reference', \n",
    "                          'bourbon_reference', 'canadian_reference']]\n",
    "                      .reset_index(), \n",
    "                      docs], \n",
    "                     axis = 1).drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined.drop(columns = 'category')\n",
    "y = combined['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ord',\n",
       "                 OrdinalEncoder(cols=['author'], drop_invariant=False,\n",
       "                                handle_missing='value', handle_unknown='value',\n",
       "                                mapping=[{'col': 'author',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': John Hansell               1\n",
       "Dave Broom                 2\n",
       "Fred Minnick               3\n",
       "Davin de Kergommeaux       4\n",
       "Gavin Smith                5\n",
       "Dominic Roskrow            6\n",
       "Geoffrey Kleinman          7\n",
       "Jonny McCormick            8\n",
       "Susannah Skiver Barton     9\n",
       "Lew Bryson                10\n",
       "Jeffery Lindenmut...\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, eval_metric='merror',\n",
       "                               gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "                               max_depth=25, min_child_weight=1, missing=None,\n",
       "                               n_estimators=200, n_jobs=-1, nthread=None,\n",
       "                               num_class=4, objective='multi:softprob',\n",
       "                               random_state=5, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, seed=42, silent=True,\n",
       "                               subsample=1, verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3 = Pipeline([('ord', encoder), ('clf', xgbc)])\n",
    "\n",
    "pipe_3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed: 12.1min remaining: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed: 12.1min remaining: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed: 12.2min remaining:  5.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third validation baseline:  0.9575708881496272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 17.9min finished\n"
     ]
    }
   ],
   "source": [
    "score_3 = (cross_val_score(pipe_3, X, y, \n",
    "                          cv = 10, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = -1,\n",
    "                          verbose = 10)).mean()\n",
    "\n",
    "print('third validation baseline: ', score_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ord',\n",
       "                 OrdinalEncoder(cols=['author'], drop_invariant=False,\n",
       "                                handle_missing='value', handle_unknown='value',\n",
       "                                mapping=[{'col': 'author',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': John Hansell               1\n",
       "Dave Broom                 2\n",
       "Fred Minnick               3\n",
       "Davin de Kergommeaux       4\n",
       "Gavin Smith                5\n",
       "Dominic Roskrow            6\n",
       "Geoffrey Kleinman          7\n",
       "Jonny McCormick            8\n",
       "Susannah Skiver Barton     9\n",
       "Lew Bryson                10\n",
       "Jeffery Lindenmut...\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4 = Pipeline([('ord', encoder), ('clf', sgdc)])\n",
    "\n",
    "pipe_4.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.2s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.4s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.7s remaining:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourth validation baseline:  0.627681442274453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.5s finished\n"
     ]
    }
   ],
   "source": [
    "score_4 = (cross_val_score(pipe_4, X, y, \n",
    "                          cv = 10, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = -1,\n",
    "                          verbose = 10)).mean()\n",
    "\n",
    "print('fourth validation baseline: ', score_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it appears the stochastic gradient descent classifier does markedly worse when provided with the non-nlp related features. However, the gradient boosting tree ensemble appears to have benefitted from the combination of the two features. The next step is to apply the feature engineering the the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = ['id','pert_alcohol','ratingValue'])\n",
    "\n",
    "scotch = []\n",
    "bourbon = []\n",
    "canadian = []\n",
    "\n",
    "for i in np.arange(len(test)):\n",
    "    for k in references:\n",
    "        ref_count = 0\n",
    "        for j in k:\n",
    "            if j in test['description'][i].lower():\n",
    "                ref_count += 1\n",
    "        if k == bourbon_references:\n",
    "            bourbon.append(ref_count)\n",
    "        elif k == scotch_references:\n",
    "            scotch.append(ref_count)\n",
    "        else:\n",
    "            canadian.append(ref_count)\n",
    "\n",
    "test['scotch_reference'] = scotch\n",
    "test['bourbon_reference'] = bourbon\n",
    "test['canadian_reference'] = canadian\n",
    "\n",
    "test['price'] = test['price'].fillna(df[df['category'] == 1]['price'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 507) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>17</th>\n",
       "      <th>20</th>\n",
       "      <th>2016</th>\n",
       "      <th>21</th>\n",
       "      <th>30</th>\n",
       "      <th>375</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yields</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156227</td>\n",
       "      <td>0.140604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10  100        12   17   20  2016   21   30  375  ...  white  wine  \\\n",
       "0  0.0  0.0  0.0  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.228406  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "       wood      year     years  yields  young  youth  youthful  zesty  \n",
       "0  0.000000  0.000000  0.000000     0.0    0.0    0.0       0.0    0.0  \n",
       "1  0.000000  0.000000  0.154227     0.0    0.0    0.0       0.0    0.0  \n",
       "2  0.000000  0.000000  0.000000     0.0    0.0    0.0       0.0    0.0  \n",
       "3  0.156227  0.140604  0.000000     0.0    0.0    0.0       0.0    0.0  \n",
       "4  0.251943  0.000000  0.000000     0.0    0.0    0.0       0.0    0.0  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                        max_features = 5000, \n",
    "                        min_df=5)\n",
    "\n",
    "dtm = tfidf.fit_transform(test['description'])\n",
    "\n",
    "docs_2 = (pd.DataFrame(dtm.todense(), \n",
    "                    columns=tfidf.get_feature_names())\n",
    "       .drop(columns = ['price']))\n",
    "\n",
    "print(docs_2.shape,'\\n')\n",
    "docs_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some creative data wrangling to get the validation dataset matching the training dataset's columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_2 = pd.concat([test[['author', 'price', \n",
    "                              'scotch_reference', \n",
    "                              'bourbon_reference', 'canadian_reference']]\n",
    "                        .reset_index(), \n",
    "                        docs_2],\n",
    "                       axis = 1).drop(columns = 'index')\n",
    "\n",
    "col_diff = list(set(X) - set(combined_2.columns))\n",
    "\n",
    "final = pd.concat([combined_2, \n",
    "                   pd.DataFrame(data=np.zeros(shape=(len(combined_2) ,\n",
    "                                                     len(col_diff))), \n",
    "                                columns=col_diff)],\n",
    "                 axis=1)\n",
    "\n",
    "final = final[X.columns]\n",
    "\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_3.predict(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.91k/1.91k [00:00<00:00, 4.14kB/s]\n",
      "Successfully submitted to DS3 Which Whisky"
     ]
    }
   ],
   "source": [
    "sample_submission['category'] = y_pred.astype(int)\n",
    "sample_submission.to_csv('hopefully_this_works.csv', index=False)\n",
    "!kaggle competitions submit -c ds3-which-whisky -f hopefully_this_works.csv -m \"Once more with feeling!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method netted a 0.96511 Accuracy score on the public leaderboard. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python 3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
